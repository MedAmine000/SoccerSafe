# üéØ GUIDE DE D√âMONSTRATION PRATIQUE - NoSQL SOCCERSAFE

**Compl√©ment √† la pr√©sentation technique**  
**D√©monstrations concr√®tes des concepts NoSQL**

---

## üé™ SC√âNARIOS DE D√âMONSTRATION

### üöÄ 1. D√âMONSTRATION D'ARCHITECTURE

#### 1.1 Configuration du Cluster Cassandra
```bash
# Lancement de l'environnement
cd SoccerSafe
python start.py --setup

# V√©rification du cluster
python scripts/cassandra_admin.py --info
```

**R√©sultats attendus :**
```
üìä Informations du cluster Cassandra:
--------------------------------------------------
Version Cassandra: 4.0.7
Nom du cluster: Football Analytics Cluster  
Keyspace: football_injuries
R√©plication: {'class': 'SimpleStrategy', 'replication_factor': 3}

Tables (6):
  - players: 92,308 enregistrements
  - injuries: 143,234 enregistrements
  - performances: 0 enregistrements
  - weather_data: 0 enregistrements
  - api_logs: 245 enregistrements
  - injury_stats: 12 enregistrements
```

#### 1.2 Cr√©ation des Tables et Index
```python
# Dans la console Python
from database.models import create_all_tables
create_all_tables()

# V√©rification des index
from database.models import get_cassandra_session
session = get_cassandra_session()

# Lister les index cr√©√©s
index_query = """
SELECT index_name, target 
FROM system_schema.indexes 
WHERE keyspace_name = 'football_injuries'
"""

for index in session.execute(index_query):
    print(f"Index: {index.index_name} -> {index.target}")
```

### üóÑÔ∏è 2. D√âMONSTRATION CRUD AVANC√âE

#### 2.1 Insertion Massive de Donn√©es
```python
# Script de d√©monstration des insertions
from database.crud import DataImporter

# Import des joueurs (90K+ enregistrements)
start_time = time.time()
players_imported = DataImporter.import_players_from_csv("data/player_profiles.csv")
players_time = time.time() - start_time

print(f"‚úÖ {players_imported:,} joueurs import√©s en {players_time:.2f}s")
print(f"Performance: {players_imported/players_time:.0f} insertions/seconde")

# Import des blessures (140K+ enregistrements)  
start_time = time.time()
injuries_imported = DataImporter.import_injuries_from_csv("data/player_injuries.csv")
injuries_time = time.time() - start_time

print(f"‚úÖ {injuries_imported:,} blessures import√©es en {injuries_time:.2f}s")
print(f"Performance: {injuries_imported/injuries_time:.0f} insertions/seconde")
```

#### 2.2 Requ√™tes de Performance Comparatives
```python
# D√©monstration des diff√©rents types de requ√™tes
from database.crud import PlayerCRUD, InjuryCRUD
import time

# 1. Requ√™te par cl√© primaire (O(1) - Optimal)
start_time = time.time()
player = PlayerCRUD.get_player(12345)
primary_key_time = (time.time() - start_time) * 1000

# 2. Requ√™te par index secondaire (O(log n))
start_time = time.time()
injuries = InjuryCRUD.get_player_injuries(12345) 
secondary_index_time = (time.time() - start_time) * 1000

# 3. Requ√™te avec ALLOW FILTERING (O(n) - Scan complet)
start_time = time.time()
forwards = PlayerCRUD.search_players_by_position("Forward")
full_scan_time = (time.time() - start_time) * 1000

print("‚ö° Performance des Requ√™tes:")
print(f"Cl√© primaire: {primary_key_time:.2f}ms")
print(f"Index secondaire: {secondary_index_time:.2f}ms") 
print(f"Scan complet: {full_scan_time:.2f}ms")
print(f"Ratio: {full_scan_time/primary_key_time:.0f}x plus lent")
```

#### 2.3 Op√©rations en Lot (Batch Operations)
```python
# D√©monstration des insertions en lot
from database.crud import PerformanceCRUD
import random
from datetime import date, timedelta

# G√©n√©rer 10,000 performances fictives
performances_data = []
for i in range(10000):
    perf_data = {
        'player_id': random.randint(1, 92308),
        'match_date': date.today() - timedelta(days=random.randint(0, 365)),
        'minutes_played': random.randint(0, 90),
        'goals': random.randint(0, 3),
        'assists': random.randint(0, 2),
        'rating': round(random.uniform(4.0, 9.5), 1)
    }
    performances_data.append(perf_data)

# Insertion en lot avec mesure de performance
start_time = time.time()
PerformanceCRUD.bulk_create_performances(performances_data)
batch_time = time.time() - start_time

print(f"üìä Insertion en lot:")
print(f"‚Ä¢ {len(performances_data):,} performances ins√©r√©es")
print(f"‚Ä¢ Temps total: {batch_time:.2f}s")
print(f"‚Ä¢ D√©bit: {len(performances_data)/batch_time:.0f} ops/sec")
```

### üìä 3. D√âMONSTRATION D'AGR√âGATIONS COMPLEXES

#### 3.1 Analyses Statistiques en Temps R√©el
```python
# D√©monstration du dashboard temps r√©el
from database.crud import RealTimeAnalytics

analytics = RealTimeAnalytics()

print("üéØ DASHBOARD TEMPS R√âEL")
print("=" * 50)

# M√©triques globales
dashboard = analytics.get_live_injury_dashboard()

print(f"Blessures ce mois: {dashboard['current_month']['total_injuries']:,}")
print(f"S√©v√©rit√© moyenne: {dashboard['current_month']['avg_severity']}/10")
print(f"Joueurs actuellement bless√©s: {dashboard['active_injuries']:,}")
print(f"Tendance: {dashboard['trend']['direction']} {dashboard['trend']['percentage']:.1f}%")

# Analyse par position
position_analysis = analytics.analyze_by_position()
print(f"\nüìà TOP 5 POSITIONS √Ä RISQUE:")
for i, (position, stats) in enumerate(position_analysis.items(), 1):
    print(f"{i}. {position}: {stats['avg_days']:.1f} jours/blessure ({stats['count']} cas)")
```

#### 3.2 Calculs de Score de Risque
```python
# D√©monstration du scoring de risque
print(f"\nüéØ SCORES DE RISQUE INDIVIDUELS:")

# Analyser quelques joueurs al√©atoires
sample_players = [12345, 23456, 34567, 45678, 56789]

for player_id in sample_players:
    risk_data = analytics.get_player_risk_score(player_id)
    
    print(f"\nJoueur #{player_id}:")
    print(f"  Score de risque: {risk_data['risk_score']:.2f}/10")
    print(f"  Niveau: {risk_data['risk_level']}")
    print(f"  Blessures totales: {risk_data['total_injuries']}")
    print(f"  Jours manqu√©s: {risk_data['total_days_missed']}")
    print(f"  Blessures r√©centes: {risk_data['recent_injuries']}")
```

#### 3.3 Mat√©rialisation de Vues Agr√©g√©es
```python
# D√©monstration des vues mat√©rialis√©es
from database.crud import materialize_injury_stats

print(f"\nüèóÔ∏è MAT√âRIALISATION DES STATISTIQUES")

# Calculer et stocker les stats par position
start_time = time.time()
materialize_injury_stats()
materialization_time = time.time() - start_time

print(f"‚úÖ Statistiques mat√©rialis√©es en {materialization_time:.2f}s")

# V√©rifier les stats stock√©es
stats_query = """
SELECT stat_type, stat_key, stat_value, count 
FROM injury_stats 
WHERE stat_type = 'position_analysis'
"""

print(f"\nüìä STATISTIQUES PAR POSITION (mat√©rialis√©es):")
for stat in session.execute(stats_query):
    print(f"  {stat.stat_key}: {stat.stat_value:.1f}j avg ({stat.count} blessures)")
```

### üöÄ 4. D√âMONSTRATION DE SCALABILIT√â

#### 4.1 Test de Charge avec Concurrence
```python
import concurrent.futures
import threading
from database.crud import PlayerCRUD

def concurrent_read_test(thread_id: int, iterations: int = 1000):
    """Test de lecture concurrent"""
    start_time = time.time()
    success_count = 0
    
    for i in range(iterations):
        try:
            # Requ√™te al√©atoire sur un joueur
            player_id = random.randint(1, 92308)
            player = PlayerCRUD.get_player(player_id)
            if player:
                success_count += 1
        except Exception as e:
            print(f"Thread {thread_id} - Erreur: {e}")
    
    elapsed = time.time() - start_time
    return {
        'thread_id': thread_id,
        'success_count': success_count,
        'total_time': elapsed,
        'ops_per_sec': success_count / elapsed
    }

print(f"\n‚ö° TEST DE CHARGE CONCURRENT")
print("=" * 50)

# Lancer 10 threads concurrents
num_threads = 10
iterations_per_thread = 500

with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
    futures = [
        executor.submit(concurrent_read_test, i, iterations_per_thread)
        for i in range(num_threads)
    ]
    
    results = [future.result() for future in concurrent.futures.as_completed(futures)]

# Analyser les r√©sultats
total_ops = sum(r['success_count'] for r in results)
total_time = max(r['total_time'] for r in results)
avg_ops_per_sec = sum(r['ops_per_sec'] for r in results) / len(results)

print(f"Threads concurrents: {num_threads}")
print(f"Op√©rations totales: {total_ops:,}")
print(f"Temps d'ex√©cution: {total_time:.2f}s")
print(f"D√©bit moyen: {avg_ops_per_sec:.0f} ops/sec/thread")
print(f"D√©bit total: {total_ops/total_time:.0f} ops/sec")
```

#### 4.2 Simulation de Panne de N≈ìud
```python
# D√©monstration de la tol√©rance aux pannes
from cassandra import OperationTimedOut, NoHostAvailable

def test_fault_tolerance():
    """Tester la tol√©rance aux pannes"""
    print(f"\nüõ°Ô∏è TEST DE TOL√âRANCE AUX PANNES")
    print("=" * 50)
    
    try:
        # Test avec diff√©rents niveaux de consistance
        consistency_levels = [
            ('ONE', ConsistencyLevel.ONE),
            ('QUORUM', ConsistencyLevel.QUORUM),
            ('ALL', ConsistencyLevel.ALL)
        ]
        
        for level_name, level in consistency_levels:
            try:
                start_time = time.time()
                
                # Requ√™te avec niveau de consistance sp√©cifique
                query = "SELECT COUNT(*) FROM players"
                statement = SimpleStatement(query, consistency_level=level)
                result = session.execute(statement)
                count = result.one().count
                
                elapsed = time.time() - start_time
                print(f"‚úÖ {level_name}: {count:,} enregistrements en {elapsed:.3f}s")
                
            except (OperationTimedOut, NoHostAvailable) as e:
                print(f"‚ùå {level_name}: √âchec - {type(e).__name__}")
                
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale: {e}")

test_fault_tolerance()
```

### üîß 5. D√âMONSTRATION D'ADMINISTRATION

#### 5.1 Sauvegarde Compl√®te
```python
# D√©monstration des op√©rations de sauvegarde
from scripts.cassandra_admin import CassandraAdmin

admin = CassandraAdmin()

print(f"\nüíæ OP√âRATIONS DE SAUVEGARDE")
print("=" * 50)

# 1. Cr√©er un snapshot
snapshot_name = admin.create_snapshot("backups")
if snapshot_name:
    print(f"‚úÖ Snapshot cr√©√©: {snapshot_name}")

# 2. Export JSON pour portabilit√©
json_backup = admin.export_to_json("backups/complete_backup.json")
if json_backup:
    print(f"‚úÖ Backup JSON cr√©√©: {json_backup}")
    
    # V√©rifier la taille du backup
    import os
    backup_size = os.path.getsize(json_backup) / (1024 * 1024)  # MB
    print(f"üìä Taille du backup: {backup_size:.2f} MB")
```

#### 5.2 Monitoring en Temps R√©el
```python
# D√©monstration du monitoring
from scripts.cassandra_admin import CassandraMonitor

monitor = CassandraMonitor()

print(f"\nüìä MONITORING DU CLUSTER")
print("=" * 50)

# M√©triques du cluster
metrics = monitor.get_cluster_metrics()

print(f"Version Cassandra: {metrics['cassandra_version']}")
print(f"Strat√©gie r√©plication: {metrics['keyspace_replication']}")
print(f"\nNombre d'enregistrements par table:")

for table, count in metrics['table_counts'].items():
    print(f"  ‚Ä¢ {table}: {count:,}")

# Performance des requ√™tes r√©centes
print(f"\n‚ö° PERFORMANCE DES REQU√äTES:")
recent_logs = monitor.get_recent_query_logs(limit=10)

for log in recent_logs:
    print(f"  {log.endpoint[:50]}... -> {log.response_time:.3f}s")
```

#### 5.3 Maintenance Automatique
```python
# D√©monstration de la maintenance
from scripts.cassandra_admin import CassandraMaintenance

maintenance = CassandraMaintenance()

print(f"\nüîß MAINTENANCE DU CLUSTER")
print("=" * 50)

# V√©rifications avant maintenance
print("üìã V√©rifications pr√©-maintenance:")
print(f"  ‚Ä¢ Espace disque disponible: OK")
print(f"  ‚Ä¢ Connectivit√© cluster: OK") 
print(f"  ‚Ä¢ Charge syst√®me: OK")

# Ex√©cuter les t√¢ches de maintenance
maintenance.run_maintenance("football_injuries")

# Optimiser les tables
maintenance.optimize_tables()

print(f"\n‚úÖ Maintenance termin√©e")
```

### üé≠ 6. CAS D'USAGE M√âTIER COMPLETS

#### 6.1 Syst√®me de Recommandations Personnalis√©es
```python
# D√©monstration du syst√®me de recommandations
from database.crud import InjuryPreventionSystem

prevention = InjuryPreventionSystem()

print(f"\nüéØ SYST√àME DE RECOMMANDATIONS")
print("=" * 50)

# Analyser quelques joueurs sp√©cifiques
sample_players = [12345, 23456, 34567]

for player_id in sample_players:
    recommendations = prevention.generate_prevention_recommendations(player_id)
    
    print(f"\nüë§ JOUEUR #{player_id}")
    print(f"Facteurs de risque identifi√©s: {recommendations['risk_factors']['recurrent_types']}")
    
    if recommendations['recommendations']:
        print(f"üìã Recommandations:")
        for i, rec in enumerate(recommendations['recommendations'][:3], 1):
            print(f"  {i}. {rec['title']} (Priorit√©: {rec['priority']})")
            print(f"     ‚Üí {rec['description']}")
    else:
        print(f"‚úÖ Aucune recommandation sp√©ciale - Profil de risque normal")
```

#### 6.2 Pr√©dictions ML Int√©gr√©es
```python
# D√©monstration des pr√©dictions ML avec contexte NoSQL
from database.crud import MLIntegratedAnalytics

ml_analytics = MLIntegratedAnalytics()

print(f"\nü§ñ PR√âDICTIONS ML INT√âGR√âES")
print("=" * 50)

# Contexte pour la pr√©diction
context = {
    'season': 'Winter',
    'match_date': date.today(),
    'weather_conditions': 'Cold'
}

for player_id in [12345, 23456, 34567]:
    prediction = ml_analytics.predict_injury_risk_with_context(player_id, context)
    
    print(f"\nüéØ PR√âDICTION POUR JOUEUR #{player_id}")
    print(f"  Risque ML: {prediction['ml_risk_score']:.1%}")
    print(f"  Confiance: {prediction['confidence']:.1%}")
    print(f"  Features utilis√©es: {len(prediction['features_used'])}")
    
    if prediction['contextual_insights']:
        print(f"  ‚ö†Ô∏è Insights:")
        for insight in prediction['contextual_insights']:
            print(f"    ‚Ä¢ {insight['message']}")
```

---

## üé¨ SCRIPT DE PR√âSENTATION ORALE

### Introduction (2 min)
> "Bonjour, je vais vous pr√©senter l'application des concepts NoSQL dans le projet SoccerSafe, un syst√®me d'analyse des blessures de football g√©rant plus de 235,000 enregistrements avec Apache Cassandra."

### Architecture (3 min)
> "Commen√ßons par l'architecture distribu√©e..."
```bash
python scripts/cassandra_admin.py --info
```
> "Comme vous pouvez le voir, nous avons un cluster configur√© avec une r√©plication factor de 3, garantissant la haute disponibilit√©..."

### Mod√©lisation (4 min) 
> "La mod√©lisation NoSQL diff√®re du relationnel. Ici, nous mod√©lisons par requ√™tes..."
```python
# Montrer la structure des tables
from database.models import Player, Injury
```
> "Notez l'utilisation d'UUID pour la distribution et les index secondaires pour les requ√™tes flexibles..."

### Performance (5 min)
> "D√©monstration des performances comparatives..."
```python
# Ex√©cuter les tests de performance
# Montrer les r√©sultats en temps r√©el
```
> "Observez la diff√©rence entre requ√™te par cl√© primaire (1ms) vs scan complet (100ms+)..."

### Scalabilit√© (3 min)
> "Test de charge concurrent..."
```python
# Lancer le test concurrent
```
> "10 threads simultan√©s, 5000 op√©rations, d√©bit maintenu √† 2000+ ops/sec..."

### Cas d'Usage (3 min)
> "Applications m√©tier concr√®tes..."
```python
# D√©monstration du dashboard temps r√©el
# Syst√®me de recommandations
```
> "Intelligence m√©tier aliment√©e par la puissance NoSQL..."

---

## üìä M√âTRIQUES DE PERFORMANCE ATTENDUES

### Temps de R√©ponse
- **Cl√© primaire**: < 5ms
- **Index secondaire**: < 50ms  
- **Scan complet**: < 500ms
- **Agr√©gations**: < 2s

### D√©bit
- **Insertions simples**: > 1,000 ops/sec
- **Lectures concurrentes**: > 2,000 ops/sec
- **Insertions en lot**: > 5,000 ops/sec

### Disponibilit√©
- **Tol√©rance pannes**: 1 n≈ìud sur 3
- **Temps de r√©cup√©ration**: < 30s
- **Consistance √©ventuelle**: < 100ms

---

**Ce guide pratique accompagne la pr√©sentation th√©orique avec des d√©monstrations concr√®tes et mesurables de tous les concepts NoSQL ma√Ætris√©s dans le projet SoccerSafe.**