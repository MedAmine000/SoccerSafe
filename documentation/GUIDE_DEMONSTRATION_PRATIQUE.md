# ğŸ¯ GUIDE DE DÃ‰MONSTRATION PRATIQUE - NoSQL SOCCERSAFE

**ComplÃ©ment Ã  la prÃ©sentation technique**  
**DÃ©monstrations concrÃ¨tes des concepts NoSQL**

---

## ğŸª SCÃ‰NARIOS DE DÃ‰MONSTRATION

### ğŸš€ 1. DÃ‰MONSTRATION D'ARCHITECTURE

#### 1.1 Configuration du Cluster Cassandra
```bash
# Lancement de l'environnement
cd SoccerSafe
python start.py --setup

# VÃ©rification du cluster
python scripts/cassandra_admin.py --info
```

**RÃ©sultats attendus :**
```
ğŸ“Š Informations du cluster Cassandra:
--------------------------------------------------
Version Cassandra: 4.0.7
Nom du cluster: Football Analytics Cluster  
Keyspace: football_injuries
RÃ©plication: {'class': 'SimpleStrategy', 'replication_factor': 3}

Tables (6):
  - players: 92,308 enregistrements
  - injuries: 143,234 enregistrements
  - performances: 0 enregistrements
  - weather_data: 0 enregistrements
  - api_logs: 245 enregistrements
  - injury_stats: 12 enregistrements
```

#### 1.2 CrÃ©ation des Tables et Index
```python
# Dans la console Python
from database.models import create_all_tables
create_all_tables()

# VÃ©rification des index
from database.models import get_cassandra_session
session = get_cassandra_session()

# Lister les index crÃ©Ã©s
index_query = """
SELECT index_name, target 
FROM system_schema.indexes 
WHERE keyspace_name = 'football_injuries'
"""

for index in session.execute(index_query):
    print(f"Index: {index.index_name} -> {index.target}")
```

### ğŸ—„ï¸ 2. DÃ‰MONSTRATION CRUD AVANCÃ‰E

#### 2.1 Insertion Massive de DonnÃ©es
```python
# Script de dÃ©monstration des insertions
from database.crud import DataImporter

# Import des joueurs (90K+ enregistrements)
start_time = time.time()
players_imported = DataImporter.import_players_from_csv("data/player_profiles.csv")
players_time = time.time() - start_time

print(f"âœ… {players_imported:,} joueurs importÃ©s en {players_time:.2f}s")
print(f"Performance: {players_imported/players_time:.0f} insertions/seconde")

# Import des blessures (140K+ enregistrements)  
start_time = time.time()
injuries_imported = DataImporter.import_injuries_from_csv("data/player_injuries.csv")
injuries_time = time.time() - start_time

print(f"âœ… {injuries_imported:,} blessures importÃ©es en {injuries_time:.2f}s")
print(f"Performance: {injuries_imported/injuries_time:.0f} insertions/seconde")
```

#### 2.2 RequÃªtes de Performance Comparatives
```python
# DÃ©monstration des diffÃ©rents types de requÃªtes
from database.crud import PlayerCRUD, InjuryCRUD
import time

# 1. RequÃªte par clÃ© primaire (O(1) - Optimal)
start_time = time.time()
player = PlayerCRUD.get_player(12345)
primary_key_time = (time.time() - start_time) * 1000

# 2. RequÃªte par index secondaire (O(log n))
start_time = time.time()
injuries = InjuryCRUD.get_player_injuries(12345) 
secondary_index_time = (time.time() - start_time) * 1000

# 3. RequÃªte avec ALLOW FILTERING (O(n) - Scan complet)
start_time = time.time()
forwards = PlayerCRUD.search_players_by_position("Forward")
full_scan_time = (time.time() - start_time) * 1000

print("âš¡ Performance des RequÃªtes:")
print(f"ClÃ© primaire: {primary_key_time:.2f}ms")
print(f"Index secondaire: {secondary_index_time:.2f}ms") 
print(f"Scan complet: {full_scan_time:.2f}ms")
print(f"Ratio: {full_scan_time/primary_key_time:.0f}x plus lent")
```

#### 2.3 OpÃ©rations en Lot (Batch Operations)
```python
# DÃ©monstration des insertions en lot
from database.crud import PerformanceCRUD
import random
from datetime import date, timedelta

# GÃ©nÃ©rer 10,000 performances fictives
performances_data = []
for i in range(10000):
    perf_data = {
        'player_id': random.randint(1, 92308),
        'match_date': date.today() - timedelta(days=random.randint(0, 365)),
        'minutes_played': random.randint(0, 90),
        'goals': random.randint(0, 3),
        'assists': random.randint(0, 2),
        'rating': round(random.uniform(4.0, 9.5), 1)
    }
    performances_data.append(perf_data)

# Insertion en lot avec mesure de performance
start_time = time.time()
PerformanceCRUD.bulk_create_performances(performances_data)
batch_time = time.time() - start_time

print(f"ğŸ“Š Insertion en lot:")
print(f"â€¢ {len(performances_data):,} performances insÃ©rÃ©es")
print(f"â€¢ Temps total: {batch_time:.2f}s")
print(f"â€¢ DÃ©bit: {len(performances_data)/batch_time:.0f} ops/sec")
```

### ğŸ“Š 3. DÃ‰MONSTRATION D'AGRÃ‰GATIONS COMPLEXES

#### 3.1 Analyses Statistiques en Temps RÃ©el
```python
# DÃ©monstration du dashboard temps rÃ©el
from database.crud import RealTimeAnalytics

analytics = RealTimeAnalytics()

print("ğŸ¯ DASHBOARD TEMPS RÃ‰EL")
print("=" * 50)

# MÃ©triques globales
dashboard = analytics.get_live_injury_dashboard()

print(f"Blessures ce mois: {dashboard['current_month']['total_injuries']:,}")
print(f"SÃ©vÃ©ritÃ© moyenne: {dashboard['current_month']['avg_severity']}/10")
print(f"Joueurs actuellement blessÃ©s: {dashboard['active_injuries']:,}")
print(f"Tendance: {dashboard['trend']['direction']} {dashboard['trend']['percentage']:.1f}%")

# Analyse par position
position_analysis = analytics.analyze_by_position()
print(f"\nğŸ“ˆ TOP 5 POSITIONS Ã€ RISQUE:")
for i, (position, stats) in enumerate(position_analysis.items(), 1):
    print(f"{i}. {position}: {stats['avg_days']:.1f} jours/blessure ({stats['count']} cas)")
```

#### 3.2 Calculs de Score de Risque
```python
# DÃ©monstration du scoring de risque
print(f"\nğŸ¯ SCORES DE RISQUE INDIVIDUELS:")

# Analyser quelques joueurs alÃ©atoires
sample_players = [12345, 23456, 34567, 45678, 56789]

for player_id in sample_players:
    risk_data = analytics.get_player_risk_score(player_id)
    
    print(f"\nJoueur #{player_id}:")
    print(f"  Score de risque: {risk_data['risk_score']:.2f}/10")
    print(f"  Niveau: {risk_data['risk_level']}")
    print(f"  Blessures totales: {risk_data['total_injuries']}")
    print(f"  Jours manquÃ©s: {risk_data['total_days_missed']}")
    print(f"  Blessures rÃ©centes: {risk_data['recent_injuries']}")
```

#### 3.3 MatÃ©rialisation de Vues AgrÃ©gÃ©es
```python
# DÃ©monstration des vues matÃ©rialisÃ©es
from database.crud import materialize_injury_stats

print(f"\nğŸ—ï¸ MATÃ‰RIALISATION DES STATISTIQUES")

# Calculer et stocker les stats par position
start_time = time.time()
materialize_injury_stats()
materialization_time = time.time() - start_time

print(f"âœ… Statistiques matÃ©rialisÃ©es en {materialization_time:.2f}s")

# VÃ©rifier les stats stockÃ©es
stats_query = """
SELECT stat_type, stat_key, stat_value, count 
FROM injury_stats 
WHERE stat_type = 'position_analysis'
"""

print(f"\nğŸ“Š STATISTIQUES PAR POSITION (matÃ©rialisÃ©es):")
for stat in session.execute(stats_query):
    print(f"  {stat.stat_key}: {stat.stat_value:.1f}j avg ({stat.count} blessures)")
```

### ğŸš€ 4. DÃ‰MONSTRATION DE SCALABILITÃ‰

#### 4.1 Test de Charge avec Concurrence
```python
import concurrent.futures
import threading
from database.crud import PlayerCRUD

def concurrent_read_test(thread_id: int, iterations: int = 1000):
    """Test de lecture concurrent"""
    start_time = time.time()
    success_count = 0
    
    for i in range(iterations):
        try:
            # RequÃªte alÃ©atoire sur un joueur
            player_id = random.randint(1, 92308)
            player = PlayerCRUD.get_player(player_id)
            if player:
                success_count += 1
        except Exception as e:
            print(f"Thread {thread_id} - Erreur: {e}")
    
    elapsed = time.time() - start_time
    return {
        'thread_id': thread_id,
        'success_count': success_count,
        'total_time': elapsed,
        'ops_per_sec': success_count / elapsed
    }

print(f"\nâš¡ TEST DE CHARGE CONCURRENT")
print("=" * 50)

# Lancer 10 threads concurrents
num_threads = 10
iterations_per_thread = 500

with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
    futures = [
        executor.submit(concurrent_read_test, i, iterations_per_thread)
        for i in range(num_threads)
    ]
    
    results = [future.result() for future in concurrent.futures.as_completed(futures)]

# Analyser les rÃ©sultats
total_ops = sum(r['success_count'] for r in results)
total_time = max(r['total_time'] for r in results)
avg_ops_per_sec = sum(r['ops_per_sec'] for r in results) / len(results)

print(f"Threads concurrents: {num_threads}")
print(f"OpÃ©rations totales: {total_ops:,}")
print(f"Temps d'exÃ©cution: {total_time:.2f}s")
print(f"DÃ©bit moyen: {avg_ops_per_sec:.0f} ops/sec/thread")
print(f"DÃ©bit total: {total_ops/total_time:.0f} ops/sec")
```

#### 4.2 Simulation de Panne de NÅ“ud
```python
# DÃ©monstration de la tolÃ©rance aux pannes
from cassandra import OperationTimedOut, NoHostAvailable

def test_fault_tolerance():
    """Tester la tolÃ©rance aux pannes"""
    print(f"\nğŸ›¡ï¸ TEST DE TOLÃ‰RANCE AUX PANNES")
    print("=" * 50)
    
    try:
        # Test avec diffÃ©rents niveaux de consistance
        consistency_levels = [
            ('ONE', ConsistencyLevel.ONE),
            ('QUORUM', ConsistencyLevel.QUORUM),
            ('ALL', ConsistencyLevel.ALL)
        ]
        
        for level_name, level in consistency_levels:
            try:
                start_time = time.time()
                
                # RequÃªte avec niveau de consistance spÃ©cifique
                query = "SELECT COUNT(*) FROM players"
                statement = SimpleStatement(query, consistency_level=level)
                result = session.execute(statement)
                count = result.one().count
                
                elapsed = time.time() - start_time
                print(f"âœ… {level_name}: {count:,} enregistrements en {elapsed:.3f}s")
                
            except (OperationTimedOut, NoHostAvailable) as e:
                print(f"âŒ {level_name}: Ã‰chec - {type(e).__name__}")
                
    except Exception as e:
        print(f"âŒ Erreur gÃ©nÃ©rale: {e}")

test_fault_tolerance()
```

### ğŸ”§ 5. DÃ‰MONSTRATION D'ADMINISTRATION

#### 5.1 Sauvegarde ComplÃ¨te
```python
# DÃ©monstration des opÃ©rations de sauvegarde
from scripts.cassandra_admin import CassandraAdmin

admin = CassandraAdmin()

print(f"\nğŸ’¾ OPÃ‰RATIONS DE SAUVEGARDE")
print("=" * 50)

# 1. CrÃ©er un snapshot
snapshot_name = admin.create_snapshot("backups")
if snapshot_name:
    print(f"âœ… Snapshot crÃ©Ã©: {snapshot_name}")

# 2. Export JSON pour portabilitÃ©
json_backup = admin.export_to_json("backups/complete_backup.json")
if json_backup:
    print(f"âœ… Backup JSON crÃ©Ã©: {json_backup}")
    
    # VÃ©rifier la taille du backup
    import os
    backup_size = os.path.getsize(json_backup) / (1024 * 1024)  # MB
    print(f"ğŸ“Š Taille du backup: {backup_size:.2f} MB")
```

#### 5.2 Monitoring en Temps RÃ©el
```python
# DÃ©monstration du monitoring
from scripts.cassandra_admin import CassandraMonitor

monitor = CassandraMonitor()

print(f"\nğŸ“Š MONITORING DU CLUSTER")
print("=" * 50)

# MÃ©triques du cluster
metrics = monitor.get_cluster_metrics()

print(f"Version Cassandra: {metrics['cassandra_version']}")
print(f"StratÃ©gie rÃ©plication: {metrics['keyspace_replication']}")
print(f"\nNombre d'enregistrements par table:")

for table, count in metrics['table_counts'].items():
    print(f"  â€¢ {table}: {count:,}")

# Performance des requÃªtes rÃ©centes
print(f"\nâš¡ PERFORMANCE DES REQUÃŠTES:")
recent_logs = monitor.get_recent_query_logs(limit=10)

for log in recent_logs:
    print(f"  {log.endpoint[:50]}... -> {log.response_time:.3f}s")
```

#### 5.3 Maintenance Automatique
```python
# DÃ©monstration de la maintenance
from scripts.cassandra_admin import CassandraMaintenance

maintenance = CassandraMaintenance()

print(f"\nğŸ”§ MAINTENANCE DU CLUSTER")
print("=" * 50)

# VÃ©rifications avant maintenance
print("ğŸ“‹ VÃ©rifications prÃ©-maintenance:")
print(f"  â€¢ Espace disque disponible: OK")
print(f"  â€¢ ConnectivitÃ© cluster: OK") 
print(f"  â€¢ Charge systÃ¨me: OK")

# ExÃ©cuter les tÃ¢ches de maintenance
maintenance.run_maintenance("football_injuries")

# Optimiser les tables
maintenance.optimize_tables()

print(f"\nâœ… Maintenance terminÃ©e")
```

### ğŸ­ 6. CAS D'USAGE MÃ‰TIER COMPLETS

#### 6.1 SystÃ¨me de Recommandations PersonnalisÃ©es
```python
# DÃ©monstration du systÃ¨me de recommandations
from database.crud import InjuryPreventionSystem

prevention = InjuryPreventionSystem()

print(f"\nğŸ¯ SYSTÃˆME DE RECOMMANDATIONS")
print("=" * 50)

# Analyser quelques joueurs spÃ©cifiques
sample_players = [12345, 23456, 34567]

for player_id in sample_players:
    recommendations = prevention.generate_prevention_recommendations(player_id)
    
    print(f"\nğŸ‘¤ JOUEUR #{player_id}")
    print(f"Facteurs de risque identifiÃ©s: {recommendations['risk_factors']['recurrent_types']}")
    
    if recommendations['recommendations']:
        print(f"ğŸ“‹ Recommandations:")
        for i, rec in enumerate(recommendations['recommendations'][:3], 1):
            print(f"  {i}. {rec['title']} (PrioritÃ©: {rec['priority']})")
            print(f"     â†’ {rec['description']}")
    else:
        print(f"âœ… Aucune recommandation spÃ©ciale - Profil de risque normal")
```

#### 6.2 PrÃ©dictions ML IntÃ©grÃ©es
```python
# DÃ©monstration des prÃ©dictions ML avec contexte NoSQL
from database.crud import MLIntegratedAnalytics

ml_analytics = MLIntegratedAnalytics()

print(f"\nğŸ¤– PRÃ‰DICTIONS ML INTÃ‰GRÃ‰ES")
print("=" * 50)

# Contexte pour la prÃ©diction
context = {
    'season': 'Winter',
    'match_date': date.today(),
    'weather_conditions': 'Cold'
}

for player_id in [12345, 23456, 34567]:
    prediction = ml_analytics.predict_injury_risk_with_context(player_id, context)
    
    print(f"\nğŸ¯ PRÃ‰DICTION POUR JOUEUR #{player_id}")
    print(f"  Risque ML: {prediction['ml_risk_score']:.1%}")
    print(f"  Confiance: {prediction['confidence']:.1%}")
    print(f"  Features utilisÃ©es: {len(prediction['features_used'])}")
    
    if prediction['contextual_insights']:
        print(f"  âš ï¸ Insights:")
        for insight in prediction['contextual_insights']:
            print(f"    â€¢ {insight['message']}")
```

---

## ğŸ¬ SCRIPT DE PRÃ‰SENTATION ORALE

### Introduction (2 min)
> "Bonjour, je vais vous prÃ©senter l'application des concepts NoSQL dans le projet SoccerSafe, un systÃ¨me d'analyse des blessures de football gÃ©rant plus de 235,000 enregistrements avec Apache Cassandra."

### Architecture (3 min)
> "CommenÃ§ons par l'architecture distribuÃ©e..."
```bash
python scripts/cassandra_admin.py --info
```
> "Comme vous pouvez le voir, nous avons un cluster configurÃ© avec une rÃ©plication factor de 3, garantissant la haute disponibilitÃ©..."

### ModÃ©lisation (4 min) 
> "La modÃ©lisation NoSQL diffÃ¨re du relationnel. Ici, nous modÃ©lisons par requÃªtes..."
```python
# Montrer la structure des tables
from database.models import Player, Injury
```
> "Notez l'utilisation d'UUID pour la distribution et les index secondaires pour les requÃªtes flexibles..."

### Performance (5 min)
> "DÃ©monstration des performances comparatives..."
```python
# ExÃ©cuter les tests de performance
# Montrer les rÃ©sultats en temps rÃ©el
```
> "Observez la diffÃ©rence entre requÃªte par clÃ© primaire (1ms) vs scan complet (100ms+)..."

### ScalabilitÃ© (3 min)
> "Test de charge concurrent..."
```python
# Lancer le test concurrent
```
> "10 threads simultanÃ©s, 5000 opÃ©rations, dÃ©bit maintenu Ã  2000+ ops/sec..."

### Cas d'Usage (3 min)
> "Applications mÃ©tier concrÃ¨tes..."
```python
# DÃ©monstration du dashboard temps rÃ©el
# SystÃ¨me de recommandations
```
> "Intelligence mÃ©tier alimentÃ©e par la puissance NoSQL..."

---

## ğŸ“Š MÃ‰TRIQUES DE PERFORMANCE ATTENDUES

### Temps de RÃ©ponse
- **ClÃ© primaire**: < 5ms
- **Index secondaire**: < 50ms  
- **Scan complet**: < 500ms
- **AgrÃ©gations**: < 2s

### DÃ©bit
- **Insertions simples**: > 1,000 ops/sec
- **Lectures concurrentes**: > 2,000 ops/sec
- **Insertions en lot**: > 5,000 ops/sec

### DisponibilitÃ©
- **TolÃ©rance pannes**: 1 nÅ“ud sur 3
- **Temps de rÃ©cupÃ©ration**: < 30s
- **Consistance Ã©ventuelle**: < 100ms

---

**Ce guide pratique accompagne la prÃ©sentation thÃ©orique avec des dÃ©monstrations concrÃ¨tes et mesurables de tous les concepts NoSQL maÃ®trisÃ©s dans le projet SoccerSafe.**